{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"T4","authorship_tag":"ABX9TyPwtL7dCVv4kfp+y0HS4blJ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5nc1tL9Zemfz","executionInfo":{"status":"ok","timestamp":1726588925080,"user_tz":-240,"elapsed":3492,"user":{"displayName":"Aakash Vardhan","userId":"03146811293329168388"}},"outputId":"e504f91b-d636-4214-ca62-4a9bd29069a4"},"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'qlora-finetuning'...\n","remote: Enumerating objects: 57, done.\u001b[K\n","remote: Counting objects: 100% (57/57), done.\u001b[K\n","remote: Compressing objects: 100% (40/40), done.\u001b[K\n","remote: Total 57 (delta 21), reused 46 (delta 10), pack-reused 0 (from 0)\u001b[K\n","Receiving objects: 100% (57/57), 31.30 MiB | 24.23 MiB/s, done.\n","Resolving deltas: 100% (21/21), done.\n"]}],"source":["import os\n","\n","repo_url = \"https://github.com/aakashvardhan/qlora-finetuning.git\"\n","local_dir = \"/content/qlora-finetuning.git\"\n","\n","# Check if the local directory already exists\n","if not os.path.exists(local_dir):\n","    # Clone the repository because it does not exist\n","    !git clone {repo_url}\n","else:\n","    # Change directory to the local repository\n","    %cd {local_dir}\n","    # Pull the latest changes because the repository already exists\n","    !git pull\n",""]},{"cell_type":"code","source":["%cd qlora-finetuning"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pzBlD962e7IM","executionInfo":{"status":"ok","timestamp":1726588925080,"user_tz":-240,"elapsed":5,"user":{"displayName":"Aakash Vardhan","userId":"03146811293329168388"}},"outputId":"e56f0028-138d-4b9e-af2d-210146ddb576"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/qlora-finetuning\n"]}]},{"cell_type":"code","source":["!pip install -q -r requirements.txt"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wei-NPK1fA7h","executionInfo":{"status":"ok","timestamp":1726588953841,"user_tz":-240,"elapsed":28764,"user":{"displayName":"Aakash Vardhan","userId":"03146811293329168388"}},"outputId":"a90ffdd3-9819-4dae-c441-a6ce55c9140e"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m280.1/280.1 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m474.3/474.3 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m137.5/137.5 MB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m9.7/9.7 MB\u001b[0m \u001b[31m93.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m39.9/39.9 MB\u001b[0m \u001b[31m51.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m311.4/311.4 kB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m105.7/105.7 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Building wheel for peft (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","cudf-cu12 24.4.1 requires pyarrow<15.0.0a0,>=14.0.1, but you have pyarrow 17.0.0 which is incompatible.\n","ibis-framework 8.0.0 requires pyarrow<16,>=2, but you have pyarrow 17.0.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0m"]}]},{"cell_type":"code","source":["import wandb\n","wandb.login()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":86},"id":"dgfSWZ4whKHE","executionInfo":{"status":"ok","timestamp":1726588961080,"user_tz":-240,"elapsed":7242,"user":{"displayName":"Aakash Vardhan","userId":"03146811293329168388"}},"outputId":"4bd65c3a-2575-4f00-ab4a-ccbd0a07392d"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","        window._wandbApiKey = new Promise((resolve, reject) => {\n","            function loadScript(url) {\n","            return new Promise(function(resolve, reject) {\n","                let newScript = document.createElement(\"script\");\n","                newScript.onerror = reject;\n","                newScript.onload = resolve;\n","                document.body.appendChild(newScript);\n","                newScript.src = url;\n","            });\n","            }\n","            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n","            const iframe = document.createElement('iframe')\n","            iframe.style.cssText = \"width:0;height:0;border:none\"\n","            document.body.appendChild(iframe)\n","            const handshake = new Postmate({\n","                container: iframe,\n","                url: 'https://wandb.ai/authorize'\n","            });\n","            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n","            handshake.then(function(child) {\n","                child.on('authorize', data => {\n","                    clearTimeout(timeout)\n","                    resolve(data)\n","                });\n","            });\n","            })\n","        });\n","    "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":["!python finetune-phi3.py"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uYjW4JBbfIF_","executionInfo":{"status":"ok","timestamp":1726589015067,"user_tz":-240,"elapsed":53991,"user":{"displayName":"Aakash Vardhan","userId":"03146811293329168388"}},"outputId":"ff10b49a-de1f-4f5e-f970-f7a7a4062c03"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-09-17 16:02:48.241559: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-09-17 16:02:48.265805: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-09-17 16:02:48.272836: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-09-17 16:02:48.289955: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-09-17 16:02:49.750101: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33makv1000\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.1\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/qlora-finetuning/wandb/run-20240917_160253-uvzo26ie\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mqloratest\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/akv1000/phi-3-fine-tuning\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: ğŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/akv1000/phi-3-fine-tuning/runs/uvzo26ie\u001b[0m\n","README.md: 100% 10.2k/10.2k [00:00<00:00, 31.3MB/s]\n","(â€¦)-00000-of-00001-b42a775f407cee45.parquet: 100% 39.5M/39.5M [00:00<00:00, 84.4MB/s]\n","(â€¦)-00000-of-00001-134b8fd0c89408b6.parquet: 100% 2.08M/2.08M [00:00<00:00, 22.9MB/s]\n","Generating train split: 100% 84437/84437 [00:00<00:00, 214719.35 examples/s]\n","Generating validation split: 100% 4401/4401 [00:00<00:00, 183782.68 examples/s]\n","config.json: 100% 967/967 [00:00<00:00, 2.82MB/s]\n","configuration_phi3.py: 100% 11.2k/11.2k [00:00<00:00, 22.8MB/s]\n","A new version of the following files was downloaded from https://huggingface.co/microsoft/Phi-3-mini-4k-instruct:\n","- configuration_phi3.py\n",". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n","modeling_phi3.py: 100% 73.2k/73.2k [00:00<00:00, 7.73MB/s]\n","A new version of the following files was downloaded from https://huggingface.co/microsoft/Phi-3-mini-4k-instruct:\n","- modeling_phi3.py\n",". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n","WARNING:transformers_modules.microsoft.Phi-3-mini-4k-instruct.5a516f86087853f9d560c95eb9209c1d4ed9ff69.modeling_phi3:`flash-attention` package not found, consider installing for better performance: No module named 'flash_attn'.\n","WARNING:transformers_modules.microsoft.Phi-3-mini-4k-instruct.5a516f86087853f9d560c95eb9209c1d4ed9ff69.modeling_phi3:Current `flash-attention` does not support `window_size`. Either upgrade or use `attn_implementation='eager'`.\n","model.safetensors.index.json: 100% 16.5k/16.5k [00:00<00:00, 37.9MB/s]\n","Downloading shards:   0% 0/2 [00:00<?, ?it/s]\n","model-00001-of-00002.safetensors:   0% 0.00/4.97G [00:00<?, ?B/s]\u001b[A\n","model-00001-of-00002.safetensors:   0% 10.5M/4.97G [00:00<00:51, 95.4MB/s]\u001b[A\n","model-00001-of-00002.safetensors:   1% 41.9M/4.97G [00:00<00:24, 204MB/s] \u001b[A\n","model-00001-of-00002.safetensors:   1% 73.4M/4.97G [00:00<00:20, 239MB/s]\u001b[A\n","model-00001-of-00002.safetensors:   2% 105M/4.97G [00:00<00:19, 256MB/s] \u001b[A\n","model-00001-of-00002.safetensors:   3% 136M/4.97G [00:00<00:18, 265MB/s]\u001b[A\n","model-00001-of-00002.safetensors:   3% 168M/4.97G [00:00<00:17, 275MB/s]\u001b[A\n","model-00001-of-00002.safetensors:   4% 199M/4.97G [00:00<00:17, 273MB/s]\u001b[A\n","model-00001-of-00002.safetensors:   5% 231M/4.97G [00:00<00:17, 277MB/s]\u001b[A\n","model-00001-of-00002.safetensors:   5% 262M/4.97G [00:01<00:16, 281MB/s]\u001b[A\n","model-00001-of-00002.safetensors:   6% 294M/4.97G [00:01<00:16, 280MB/s]\u001b[A\n","model-00001-of-00002.safetensors:   7% 325M/4.97G [00:01<00:16, 281MB/s]\u001b[A\n","model-00001-of-00002.safetensors:   7% 357M/4.97G [00:01<00:16, 280MB/s]\u001b[A\n","model-00001-of-00002.safetensors:   8% 388M/4.97G [00:01<00:16, 280MB/s]\u001b[A\n","model-00001-of-00002.safetensors:   8% 419M/4.97G [00:01<00:16, 282MB/s]\u001b[A\n","model-00001-of-00002.safetensors:   9% 451M/4.97G [00:01<00:16, 281MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  10% 482M/4.97G [00:01<00:15, 282MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  10% 514M/4.97G [00:01<00:15, 280MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  11% 545M/4.97G [00:02<00:15, 279MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  12% 577M/4.97G [00:02<00:15, 277MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  12% 608M/4.97G [00:02<00:15, 276MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  13% 640M/4.97G [00:02<00:16, 271MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  13% 671M/4.97G [00:02<00:15, 270MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  14% 703M/4.97G [00:02<00:16, 264MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  15% 734M/4.97G [00:02<00:16, 263MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  15% 765M/4.97G [00:02<00:15, 265MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  16% 797M/4.97G [00:02<00:15, 263MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  17% 828M/4.97G [00:03<00:15, 261MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  17% 860M/4.97G [00:03<00:15, 261MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  18% 891M/4.97G [00:03<00:15, 261MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  19% 923M/4.97G [00:03<00:15, 261MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  19% 954M/4.97G [00:03<00:15, 263MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  20% 986M/4.97G [00:03<00:15, 266MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  20% 1.02G/4.97G [00:03<00:15, 263MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  21% 1.05G/4.97G [00:03<00:14, 264MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  22% 1.08G/4.97G [00:04<00:14, 267MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  22% 1.11G/4.97G [00:04<00:14, 267MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  23% 1.14G/4.97G [00:04<00:14, 271MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  24% 1.17G/4.97G [00:04<00:13, 271MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  24% 1.21G/4.97G [00:04<00:13, 270MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  25% 1.24G/4.97G [00:04<00:13, 268MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  26% 1.27G/4.97G [00:04<00:13, 267MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  26% 1.30G/4.97G [00:04<00:13, 270MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  27% 1.33G/4.97G [00:04<00:13, 271MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  27% 1.36G/4.97G [00:05<00:13, 273MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  28% 1.39G/4.97G [00:05<00:13, 274MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  29% 1.43G/4.97G [00:05<00:12, 273MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  29% 1.46G/4.97G [00:05<00:12, 275MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  30% 1.49G/4.97G [00:05<00:12, 275MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  31% 1.52G/4.97G [00:05<00:12, 277MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  31% 1.55G/4.97G [00:05<00:12, 279MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  32% 1.58G/4.97G [00:05<00:12, 280MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  32% 1.61G/4.97G [00:05<00:11, 282MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  33% 1.65G/4.97G [00:06<00:11, 281MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  34% 1.68G/4.97G [00:06<00:11, 283MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  34% 1.71G/4.97G [00:06<00:11, 282MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  35% 1.74G/4.97G [00:06<00:11, 282MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  36% 1.77G/4.97G [00:06<00:11, 286MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  36% 1.80G/4.97G [00:06<00:11, 285MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  37% 1.84G/4.97G [00:06<00:11, 274MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  38% 1.87G/4.97G [00:06<00:11, 274MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  38% 1.90G/4.97G [00:07<00:11, 271MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  39% 1.93G/4.97G [00:07<00:11, 276MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  39% 1.96G/4.97G [00:07<00:11, 272MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  40% 1.99G/4.97G [00:07<00:11, 270MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  41% 2.02G/4.97G [00:07<00:11, 267MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  41% 2.06G/4.97G [00:07<00:10, 266MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  42% 2.09G/4.97G [00:07<00:10, 264MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  43% 2.12G/4.97G [00:07<00:10, 263MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  43% 2.15G/4.97G [00:07<00:10, 260MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  44% 2.18G/4.97G [00:08<00:10, 260MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  44% 2.21G/4.97G [00:08<00:10, 261MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  45% 2.24G/4.97G [00:08<00:10, 257MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  46% 2.28G/4.97G [00:08<00:10, 255MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  46% 2.31G/4.97G [00:08<00:10, 257MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  47% 2.34G/4.97G [00:08<00:10, 256MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  48% 2.37G/4.97G [00:08<00:10, 255MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  48% 2.40G/4.97G [00:08<00:10, 256MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  49% 2.43G/4.97G [00:09<00:09, 256MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  50% 2.46G/4.97G [00:09<00:09, 252MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  50% 2.50G/4.97G [00:09<00:09, 251MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  51% 2.53G/4.97G [00:09<00:09, 252MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  51% 2.56G/4.97G [00:09<00:09, 257MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  52% 2.59G/4.97G [00:09<00:09, 260MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  53% 2.62G/4.97G [00:09<00:08, 263MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  53% 2.65G/4.97G [00:09<00:08, 263MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  54% 2.68G/4.97G [00:10<00:08, 267MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  55% 2.72G/4.97G [00:10<00:08, 270MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  55% 2.75G/4.97G [00:10<00:08, 272MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  56% 2.78G/4.97G [00:10<00:08, 273MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  57% 2.81G/4.97G [00:10<00:07, 278MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  57% 2.84G/4.97G [00:10<00:07, 280MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  58% 2.87G/4.97G [00:10<00:07, 280MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  58% 2.90G/4.97G [00:10<00:07, 279MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  59% 2.94G/4.97G [00:10<00:07, 278MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  60% 2.97G/4.97G [00:11<00:07, 276MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  60% 3.00G/4.97G [00:11<00:07, 277MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  61% 3.03G/4.97G [00:11<00:07, 277MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  62% 3.06G/4.97G [00:11<00:06, 277MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  62% 3.09G/4.97G [00:11<00:06, 276MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  63% 3.12G/4.97G [00:11<00:06, 275MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  63% 3.16G/4.97G [00:11<00:06, 274MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  64% 3.19G/4.97G [00:11<00:06, 278MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  65% 3.22G/4.97G [00:11<00:06, 278MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  65% 3.25G/4.97G [00:12<00:06, 271MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  66% 3.28G/4.97G [00:12<00:06, 273MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  67% 3.31G/4.97G [00:12<00:06, 260MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  67% 3.34G/4.97G [00:12<00:06, 261MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  68% 3.38G/4.97G [00:12<00:06, 264MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  69% 3.41G/4.97G [00:12<00:05, 266MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  69% 3.44G/4.97G [00:12<00:05, 266MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  70% 3.47G/4.97G [00:12<00:05, 270MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  70% 3.50G/4.97G [00:13<00:05, 272MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  71% 3.53G/4.97G [00:13<00:05, 271MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  72% 3.57G/4.97G [00:13<00:05, 269MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  72% 3.60G/4.97G [00:13<00:05, 266MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  73% 3.63G/4.97G [00:13<00:05, 261MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  74% 3.66G/4.97G [00:13<00:05, 259MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  74% 3.69G/4.97G [00:13<00:04, 259MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  75% 3.72G/4.97G [00:13<00:04, 261MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  75% 3.75G/4.97G [00:13<00:04, 257MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  76% 3.79G/4.97G [00:14<00:04, 257MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  77% 3.82G/4.97G [00:14<00:04, 254MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  77% 3.85G/4.97G [00:14<00:04, 259MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  78% 3.88G/4.97G [00:14<00:04, 262MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  79% 3.91G/4.97G [00:14<00:03, 267MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  79% 3.94G/4.97G [00:14<00:03, 268MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  80% 3.97G/4.97G [00:14<00:03, 269MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  81% 4.01G/4.97G [00:14<00:03, 270MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  81% 4.04G/4.97G [00:15<00:03, 272MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  82% 4.07G/4.97G [00:15<00:03, 272MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  82% 4.10G/4.97G [00:15<00:03, 272MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  83% 4.13G/4.97G [00:15<00:03, 269MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  84% 4.16G/4.97G [00:15<00:03, 266MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  84% 4.19G/4.97G [00:15<00:02, 269MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  85% 4.23G/4.97G [00:15<00:02, 273MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  86% 4.26G/4.97G [00:15<00:02, 277MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  86% 4.29G/4.97G [00:15<00:02, 277MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  87% 4.32G/4.97G [00:16<00:02, 278MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  88% 4.35G/4.97G [00:16<00:02, 276MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  88% 4.38G/4.97G [00:16<00:02, 275MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  89% 4.41G/4.97G [00:16<00:02, 276MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  89% 4.45G/4.97G [00:16<00:01, 274MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  90% 4.48G/4.97G [00:16<00:01, 273MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  91% 4.51G/4.97G [00:16<00:01, 275MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  91% 4.54G/4.97G [00:16<00:01, 277MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  92% 4.57G/4.97G [00:16<00:01, 276MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  93% 4.60G/4.97G [00:17<00:01, 278MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  93% 4.63G/4.97G [00:17<00:01, 276MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  94% 4.67G/4.97G [00:17<00:01, 272MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  94% 4.70G/4.97G [00:17<00:01, 273MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  95% 4.73G/4.97G [00:17<00:00, 268MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  96% 4.76G/4.97G [00:17<00:00, 269MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  96% 4.79G/4.97G [00:17<00:00, 270MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  97% 4.82G/4.97G [00:17<00:00, 269MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  98% 4.85G/4.97G [00:18<00:00, 271MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  98% 4.89G/4.97G [00:18<00:00, 273MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  99% 4.92G/4.97G [00:18<00:00, 272MB/s]\u001b[A\n","model-00001-of-00002.safetensors: 100% 4.97G/4.97G [00:18<00:00, 269MB/s]\n","Downloading shards:  50% 1/2 [00:18<00:18, 18.63s/it]\n","model-00002-of-00002.safetensors:   0% 0.00/2.67G [00:00<?, ?B/s]\u001b[A\n","model-00002-of-00002.safetensors:   1% 31.5M/2.67G [00:00<00:09, 280MB/s]\u001b[A\n","model-00002-of-00002.safetensors:   2% 62.9M/2.67G [00:00<00:09, 270MB/s]\u001b[A\n","model-00002-of-00002.safetensors:   4% 94.4M/2.67G [00:00<00:09, 272MB/s]\u001b[A\n","model-00002-of-00002.safetensors:   5% 126M/2.67G [00:00<00:09, 274MB/s] \u001b[A\n","model-00002-of-00002.safetensors:   6% 157M/2.67G [00:00<00:09, 275MB/s]\u001b[A\n","model-00002-of-00002.safetensors:   7% 189M/2.67G [00:00<00:09, 274MB/s]\u001b[A\n","model-00002-of-00002.safetensors:   8% 220M/2.67G [00:00<00:09, 270MB/s]\u001b[A\n","model-00002-of-00002.safetensors:   9% 252M/2.67G [00:00<00:09, 268MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  11% 283M/2.67G [00:01<00:08, 271MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  12% 315M/2.67G [00:01<00:08, 273MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  13% 346M/2.67G [00:01<00:08, 276MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  14% 377M/2.67G [00:01<00:08, 275MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  15% 409M/2.67G [00:01<00:08, 273MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  16% 440M/2.67G [00:01<00:08, 272MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  18% 472M/2.67G [00:01<00:08, 271MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  19% 503M/2.67G [00:01<00:08, 265MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  20% 535M/2.67G [00:01<00:08, 262MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  21% 566M/2.67G [00:02<00:08, 259MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  22% 598M/2.67G [00:02<00:07, 265MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  24% 629M/2.67G [00:02<00:07, 272MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  25% 661M/2.67G [00:02<00:07, 276MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  26% 692M/2.67G [00:02<00:11, 178MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  27% 724M/2.67G [00:02<00:09, 201MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  28% 755M/2.67G [00:02<00:08, 221MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  29% 786M/2.67G [00:03<00:07, 237MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  31% 818M/2.67G [00:03<00:07, 252MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  32% 849M/2.67G [00:03<00:07, 259MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  33% 881M/2.67G [00:03<00:06, 266MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  34% 912M/2.67G [00:03<00:06, 261MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  35% 944M/2.67G [00:03<00:06, 268MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  37% 975M/2.67G [00:03<00:06, 273MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  38% 1.01G/2.67G [00:03<00:06, 274MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  39% 1.04G/2.67G [00:03<00:05, 274MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  40% 1.07G/2.67G [00:04<00:05, 277MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  41% 1.10G/2.67G [00:04<00:05, 276MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  42% 1.13G/2.67G [00:04<00:05, 276MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  44% 1.16G/2.67G [00:04<00:05, 280MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  45% 1.20G/2.67G [00:04<00:05, 280MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  46% 1.23G/2.67G [00:04<00:05, 280MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  47% 1.26G/2.67G [00:04<00:05, 282MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  48% 1.29G/2.67G [00:04<00:04, 278MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  49% 1.32G/2.67G [00:05<00:04, 277MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  51% 1.35G/2.67G [00:05<00:04, 274MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  52% 1.38G/2.67G [00:05<00:04, 275MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  53% 1.42G/2.67G [00:05<00:04, 275MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  54% 1.45G/2.67G [00:05<00:04, 274MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  55% 1.48G/2.67G [00:05<00:04, 274MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  57% 1.51G/2.67G [00:05<00:04, 270MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  58% 1.54G/2.67G [00:05<00:04, 264MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  59% 1.57G/2.67G [00:05<00:04, 262MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  60% 1.60G/2.67G [00:06<00:04, 261MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  61% 1.64G/2.67G [00:06<00:03, 261MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  62% 1.67G/2.67G [00:06<00:03, 260MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  64% 1.70G/2.67G [00:06<00:03, 261MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  65% 1.73G/2.67G [00:06<00:03, 261MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  66% 1.76G/2.67G [00:06<00:03, 260MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  67% 1.79G/2.67G [00:06<00:03, 261MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  68% 1.82G/2.67G [00:06<00:03, 266MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  70% 1.86G/2.67G [00:07<00:03, 262MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  71% 1.89G/2.67G [00:07<00:03, 258MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  72% 1.92G/2.67G [00:07<00:02, 253MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  73% 1.95G/2.67G [00:07<00:02, 257MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  74% 1.98G/2.67G [00:07<00:02, 255MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  75% 2.01G/2.67G [00:07<00:02, 256MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  77% 2.04G/2.67G [00:07<00:02, 258MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  78% 2.08G/2.67G [00:07<00:02, 262MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  79% 2.11G/2.67G [00:08<00:02, 266MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  80% 2.14G/2.67G [00:08<00:01, 270MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  81% 2.17G/2.67G [00:08<00:01, 272MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  82% 2.20G/2.67G [00:08<00:01, 276MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  84% 2.23G/2.67G [00:08<00:01, 279MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  85% 2.26G/2.67G [00:08<00:01, 280MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  86% 2.30G/2.67G [00:08<00:01, 271MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  87% 2.33G/2.67G [00:08<00:01, 274MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  88% 2.36G/2.67G [00:08<00:01, 273MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  90% 2.39G/2.67G [00:09<00:01, 268MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  91% 2.42G/2.67G [00:09<00:00, 272MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  92% 2.45G/2.67G [00:09<00:00, 274MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  93% 2.49G/2.67G [00:09<00:00, 279MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  94% 2.52G/2.67G [00:09<00:00, 282MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  95% 2.55G/2.67G [00:09<00:00, 281MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  97% 2.58G/2.67G [00:09<00:00, 280MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  98% 2.61G/2.67G [00:09<00:00, 277MB/s]\u001b[A\n","model-00002-of-00002.safetensors: 100% 2.67G/2.67G [00:10<00:00, 266MB/s]\n","Downloading shards: 100% 2/2 [00:28<00:00, 14.38s/it]\n","INFO:accelerate.utils.modeling:We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).\n","Loading checkpoint shards: 100% 2/2 [00:03<00:00,  1.76s/it]\n","generation_config.json: 100% 181/181 [00:00<00:00, 539kB/s]\n","tokenizer_config.json: 100% 3.44k/3.44k [00:00<00:00, 11.0MB/s]\n","tokenizer.model: 100% 500k/500k [00:00<00:00, 342MB/s]\n","tokenizer.json: 100% 1.94M/1.94M [00:00<00:00, 27.8MB/s]\n","added_tokens.json: 100% 306/306 [00:00<00:00, 1.15MB/s]\n","special_tokens_map.json: 100% 599/599 [00:00<00:00, 2.40MB/s]\n","Map:   0% 0/10000 [00:00<?, ? examples/s]\n","Traceback (most recent call last):\n","  File \"/content/qlora-finetuning/finetune-phi3.py\", line 97, in <module>\n","    main()\n","  File \"/content/qlora-finetuning/finetune-phi3.py\", line 32, in main\n","    train_ds, val_ds = preprocess_datasets(\n","  File \"/content/qlora-finetuning/data_processing.py\", line 65, in preprocess_datasets\n","    train_ds = train_ds.map(\n","  File \"/usr/local/lib/python3.10/dist-packages/datasets/arrow_dataset.py\", line 560, in wrapper\n","    out: Union[\"Dataset\", \"DatasetDict\"] = func(self, *args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/datasets/arrow_dataset.py\", line 3035, in map\n","    for rank, done, content in Dataset._map_single(**dataset_kwargs):\n","  File \"/usr/local/lib/python3.10/dist-packages/datasets/arrow_dataset.py\", line 3438, in _map_single\n","    batch = apply_function_on_filtered_inputs(\n","  File \"/usr/local/lib/python3.10/dist-packages/datasets/arrow_dataset.py\", line 3300, in apply_function_on_filtered_inputs\n","    processed_inputs = function(*fn_args, *additional_args, **fn_kwargs)\n","  File \"/content/qlora-finetuning/data_processing.py\", line 47, in preprocess_function\n","    for prompt, response in zip(examples[\"prompt\"], examples[\"response\"]):\n","  File \"/usr/local/lib/python3.10/dist-packages/datasets/formatting/formatting.py\", line 277, in __getitem__\n","    value = self.data[key]\n","KeyError: 'prompt'\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"3knOUEeRf3I0","executionInfo":{"status":"ok","timestamp":1726589015067,"user_tz":-240,"elapsed":2,"user":{"displayName":"Aakash Vardhan","userId":"03146811293329168388"}}},"execution_count":5,"outputs":[]}]}